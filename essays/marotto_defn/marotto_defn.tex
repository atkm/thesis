\documentclass[11pt]{book}
\usepackage{thesis}

\begin{document}
\section{Chaos in Marotto's sense}

\begin{definition}
  (Repelling fixed point)
  Let $X \subset \R^n$ be open, and $F: X \to X$ be a continuous mapping. 
  A fixed point $x_s \in X$ is said to be a repelling if there exists $r > 0$
  such that 
  \begin{equation*}
    0 < \norm{x_s - x_0} \leq r
  \end{equation*}
implies
\begin{equation*}
  r \leq \norm{x_s - F^m(x_0)}
\end{equation*}
for some $m > 0$.
\end{definition}
A repelling fixed point is sometimes referred to as a source.

\begin{definition}
  (Expanding fixed point)
  Let $X \subset \R^n$ be open, and $F: X \to X$ be a continuous mapping. 
  A fixed point $x_s \in  X$ is called an expanding fixed point if
  the magnitudes of all eigenvalues of $J$ the Jacobian matrix of $F$ at $x_s$ are strictly greater than $1$.
\end{definition}

\begin{lemma}
  (Martelli p115, 128)
  Let $M$ be a square matrix whose eigenvalues have moduli larger than 1.
  Then 
  \begin{enumerate}[(i)]
    \item $M$ is invertible.
    \item $\rho(M^{-1}) < 1$, where $\rho(M^{-1})$ denotes the spectral radius of $M^{-1}$.
    \item There exists a norm $\norm{.}_a$ such that $\norm{M}_a < 1$.
    
  \end{enumerate}
\end{lemma}
\begin{proof}
  (i) Since $0$ is not an eigenvalue of $M$, we have $\det M \neq 0$.
  Hence $M$ is invertible.

  (ii) The result follows naturally from the fact that
  $\lambda$ is an eigenvalue of $M$ if and only if $\lambda^{-1}$ is an eigenvalue of $M^{1-}$.

  (iii) 
\end{proof}

\begin{proposition}
  (Repeller implies Expanding fixed point)
  Let $X \subset \R^n$ be open, and let $x_s$ be a repelling fixed point
  of a continuous function $F: X \to X$. Suppose that $F$ is
  differentiable in some neighborhood of $x_s$, and the derivative of $F$ at $x_s$ is continuous.
  Then $x_s$ is an expanding fixed point.
\end{proposition}
\begin{proof}
  $J$ is invertible because it satisfies the conditions of the preceding lemma.
  Also, we can find a norm $\norm{.}_a$ such that $\norm{M^{-1}}_a < 1$.
  For each $x, y \in \R^n$, we have 
  \begin{equation*}
    \norm{x-y}_a = \norm{M^{-1} M x - M^{-1} M y}_a \leq \norm{M^{-1}}_a \norm{M(x - y)}_a.
  \end{equation*}
  It follows that 
  \begin{equation*}
    \frac{\norm{M(x-y)}_a}{\norm{x-y}_a} \geq \frac{1}{\norm{M^{-1}}_a}.
  \end{equation*}
  For convenience, let $K = 1/\norm{M^{-1}}_a$.
  Note that $K > 1$.
  (Martelli p188)
\end{proof}

% Let $\lambda$ be an eigenvalue of $M$. Note that
%   \begin{equation*}
%     (\lambda^{-1} I - M^{-1}) M = \lambda^{1-} M - I = \lambda^{-1} (M - \lambda I)
%   \end{equation*}
%   implies $\det ( (\lambda^{-1}I - M^{-1}) M) = 0 $ since $\det (M - \lambda I) = 0$.
%   Also, it follows from the following equation
%   \begin{equation*}
%     \det( (\lambda^{-1} I - M^{-1} ) M) = \det( (\lambda^{-1} I - M^{-1} )) \det M
%   \end{equation*}
%   that $det(\lambda^{-1} I - M^{-1}) = 0$.
%   This establishes the fact that $\lambda^{-1}$ is an eigenvalue of $M^{-1}$ if and only if $\lambda$ is an eigenvalue of $M$.
% 
\end{document}

