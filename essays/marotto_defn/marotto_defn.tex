\documentclass[11pt]{book}
\usepackage{thesis}

\begin{document}
\section{Chaos in Marotto's sense}

\begin{definition}
  (Repelling fixed point)
  Let $X \subset \R^n$ be open, and $F: X \to X$ be a continuous mapping. 
  A fixed point $x_s \in X$ is said to be a repelling if there exists $r > 0$
  such that 
  \begin{equation*}
    0 < \norm{x_s - x_0} \leq r,
  \end{equation*}
  where $\norm{.}$ is the Euclidean norm, implies
\begin{equation*}
  r \leq \norm{x_s - F^m(x_0)}
\end{equation*}
for some $m > 0$.
\end{definition}
A repelling fixed point is sometimes referred to as a source.

\begin{definition}
  (Expanding fixed point)
  Let $X \subset \R^n$ be open, and $F: X \to X$ be a continuous mapping. 
  A fixed point $x_s \in  X$ is called an expanding fixed point if
  the magnitudes of all eigenvalues of $J$ the Jacobian matrix of $F$ at $x_s$ are strictly greater than $1$.
\end{definition}

\begin{lemma}
  (Martelli p115, 128)
  Let $M$ be a square matrix whose eigenvalues have moduli larger than 1.
  Then 
  \begin{enumerate}[(i)]
    \item $M$ is invertible.
    \item $\rho(M^{-1}) < 1$, where $\rho(M^{-1})$ denotes the spectral radius of $M^{-1}$.
    \item There exists a norm $\norm{.}_a$ such that $\norm{M}_a < 1$.
    
  \end{enumerate}
\end{lemma}
\begin{proof}
  (i) Since $0$ is not an eigenvalue of $M$, we have $\det M \neq 0$.
  Hence $M$ is invertible.

  (ii) The result follows naturally from the fact that
  $\lambda$ is an eigenvalue of $M$ if and only if $\lambda^{-1}$ is an eigenvalue of $M^{1-}$.

  (iii) 
\end{proof}

\begin{proposition}
  (Repeller implies Expanding fixed point)
  (Martelli p188)
  Let $X \subset \R^n$ be open, and let $x_s$ be a repelling fixed point
  of a continuous function $F: X \to X$. Suppose that $F$ is
  differentiable in some neighborhood of $x_s$, and the derivative of $F$ at $x_s$ is continuous.
  Then $x_s$ is an expanding fixed point.
\end{proposition}
\begin{proof}
  $J$ is invertible because it satisfies the conditions of the preceding lemma.
  Also, we can find a norm $\norm{.}_a$ such that $\norm{M^{-1}}_a < 1$.
  For each $x, y \in \R^n$, we have 
  \begin{equation*}
    \norm{x-y}_a = \norm{M^{-1} M x - M^{-1} M y}_a \leq \norm{M^{-1}}_a \norm{M(x - y)}_a.
  \end{equation*}
  It follows that 
  \begin{equation*}
    \frac{\norm{M(x-y)}_a}{\norm{x-y}_a} \geq \frac{1}{\norm{M^{-1}}_a}.
  \end{equation*}
  For convenience, let $K = 1/\norm{M^{-1}}_a$.
  Note that $K > 1$.
  (fill in the blank)
  \begin{equation*}
    \frac{\norm{F(x) - F(x_s)}_a}{\norm{x - x_s}_a} \geq \frac{K+1}{2}.
  \end{equation*}
  Let $k \equiv \frac{K+1}{2}$.
  (Lemma begin) Now suppose
  \begin{equation*}
    0 < \norm{x_0 - x_s}_a \leq r_1.
  \end{equation*}
  ($r_1$ just needs to be small enough that an open ball
  of radius $r_1$ around $x_s$ does not distend over the
  neighborhood where $F$ is differentiable.) Then
  \begin{align*}
    \norm{F^n(x_0) - x_s}_a &= \norm{F(F^{n-1}) - x_s}_a \geq k \norm{F^{n-1} - x_s}_a     \\
    &= \norm{F(F^{n-2}) - x_s}_a \geq \cdots \\
    &\geq k^n \norm{x_0 - x_s}_a.
  \end{align*}
  (Lemma end)
  Since $k > 1$, we can find $n$ that satisfies the following inequality
  \begin{equation*}
    \norm{F^n(x_0) - x_s}_a > r_1.
  \end{equation*}
  By the equivalence of norms defined in $\R^n$, there exist $0 < b < c$ such that 
  \begin{equation*}
    b \norm{x_0 - x_s} \leq \norm{x_0 - x_s}_a \leq c \norm{x_0 - x_s}_a.
  \end{equation*}
  Finally, set $r \equiv r_1/c$. If we suppose that 
  \begin{equation*}
    \norm{x_0 - x_s} \leq r,
  \end{equation*}
  then
  \begin{equation*}
    \norm{x_0 - x_s}_a \leq c \norm{x_0 - x_s} \leq cr = r_1.
  \end{equation*}
  It follows by the lemma that there exists $m > 0$ such that 
  \begin{equation*}
    c \norm{F^m(x_0) - x_s} \geq \norm{F^m(x_0) - x_s}_a > r_1,
  \end{equation*}
  which implies
  \begin{equation*}
    \norm{F^{m}(x_0) - x_s} > \frac{r_1}{c} = r.
  \end{equation*}
\end{proof}

% Let $\lambda$ be an eigenvalue of $M$. Note that
%   \begin{equation*}
%     (\lambda^{-1} I - M^{-1}) M = \lambda^{1-} M - I = \lambda^{-1} (M - \lambda I)
%   \end{equation*}
%   implies $\det ( (\lambda^{-1}I - M^{-1}) M) = 0 $ since $\det (M - \lambda I) = 0$.
%   Also, it follows from the following equation
%   \begin{equation*}
%     \det( (\lambda^{-1} I - M^{-1} ) M) = \det( (\lambda^{-1} I - M^{-1} )) \det M
%   \end{equation*}
%   that $det(\lambda^{-1} I - M^{-1}) = 0$.
%   This establishes the fact that $\lambda^{-1}$ is an eigenvalue of $M^{-1}$ if and only if $\lambda$ is an eigenvalue of $M$.
% 
\end{document}

